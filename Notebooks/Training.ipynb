{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, yaml\n",
    "import sys\n",
    "\n",
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(PROJECT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from encoders import SupervisedEncoder\n",
    "from decoders import DecoderWithoutLatent, DecoderWithLatent\n",
    "from models import SupervisedAutoencoder, UnsupervisedAutoencoder\n",
    "from losses import SpectralLoss, MultiLoss\n",
    "from preprocessing import F0LoudnessPreprocessor, MidiF0LoudnessPreprocessor\n",
    "from dataloader import make_unsupervised_dataset, make_supervised_dataset\n",
    "\n",
    "from train_utils import make_supervised_model, make_unsupervised_model, create_callbacks, make_optimizer\n",
    "from train_utils import make_supervised_dataset_from_config, make_unsupervised_dataset_from_config\n",
    "from feature_extraction import process_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/Supervised_Latent_Violin_Timesteps.yaml', 'r') as file:\n",
    "    config = dict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set, _ = make_supervised_dataset('../audio_clips/Violin_short', #config['data']['path']\n",
    "                                                # extract mfcc if there is an encoder\n",
    "                                                mfcc=config['model']['encoder'],\n",
    "                                                batch_size=config['training']['batch_size'],\n",
    "                                                sample_rate=config['data']['sample_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set, _ = make_supervised_dataset_from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised DDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_supervised_model(config)\n",
    "optimizer = make_optimizer(config)\n",
    "\n",
    "model.compile(optimizer)\n",
    "print('Model Compiled.')\n",
    "history = model.fit(train_set,\n",
    "                    validation_data=validation_set,\n",
    "                    #callbacks = callbacks,\n",
    "                    epochs=config['training']['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_timesteps = 250\n",
    "decoder_timesteps = 1000\n",
    "\n",
    "preprocessor = F0LoudnessPreprocessor(timesteps=preprocessing_timesteps)\n",
    "\n",
    "# Without Latent\n",
    "encoder = None\n",
    "decoder = DecoderWithoutLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# With Latent\n",
    "#encoder = SupervisedEncoder()\n",
    "#decoder = DecoderWithLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# Choose a loss\n",
    "loss = SpectralLoss(logmag_weight=1.0)\n",
    "#loss = MultiLoss()\n",
    "\n",
    "tracker_names = ['spec_loss'] if loss.name=='spectral_loss' else ['spec_loss', 'perc_loss', 'total_loss']\n",
    "\n",
    "model = SupervisedAutoencoder(preprocessor=preprocessor,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            loss_fn=loss,\n",
    "                            tracker_names=tracker_names,\n",
    "                            add_reverb=True)\n",
    "                                \n",
    "adam = Adam(learning_rate=ExponentialDecay(1e-3, decay_steps=10000, decay_rate=0.98))\n",
    "\n",
    "model_dir = \"model_checkpoints/yeah_{}\".format(config['run_name'])\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "#callbacks = [ModelCheckpoint(filepath=os.path.join(model_dir, 'model.ckpt'),\n",
    "#                              monitor='val_spec_loss' if loss.name=='spectral_loss' else 'val_total_loss',\n",
    "#                              save_best_only=True)]\n",
    "\n",
    "callbacks = [ModelCheckpoint(model_dir,\n",
    "               monitor='val_spec_loss' if loss.name=='spectral_loss' else 'val_total_loss')]\n",
    "\n",
    "#csv_logger = tf.keras.callbacks.CSVLogger(\"logs/{}.csv\".format(RUN_NAME), separator=\",\", append=False)\n",
    "#callbacks = [ModelCheckpoint(model, RUN_NAME), csv_logger]\n",
    "#callbacks.append(CustomWandbCallback(RUN_NAME)) # uncomment for WANDB\n",
    "\n",
    "model.compile(adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_set, validation_data=validation_set, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_timesteps = 250\n",
    "decoder_timesteps = 1000\n",
    "\n",
    "preprocessor = F0LoudnessPreprocessor(timesteps=preprocessing_timesteps)\n",
    "\n",
    "# Without Latent\n",
    "encoder = None\n",
    "decoder = DecoderWithoutLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# With Latent\n",
    "#encoder = SupervisedEncoder()\n",
    "#decoder = DecoderWithLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# Choose a loss\n",
    "loss = SpectralLoss(logmag_weight=1.0)\n",
    "#loss = MultiLoss()\n",
    "\n",
    "tracker_names = ['spec_loss'] if loss.name=='spectral_loss' else ['spec_loss', 'perc_loss', 'total_loss']\n",
    "\n",
    "model = SupervisedAutoencoder(preprocessor=preprocessor,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            loss_fn=loss,\n",
    "                            tracker_names=tracker_names,\n",
    "                            add_reverb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised DDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import f0_midi_scaled_L1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/Unsupervised_Violin.yaml', 'r') as file:\n",
    "    config = dict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/hbalim15/.local/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/kuacc/users/hbalim15/.local/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n"
     ]
    }
   ],
   "source": [
    "train, val, _ = make_unsupervised_dataset_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = make_unsupervised_model(config)\n",
    "optimizer = make_optimizer(config)\n",
    "\n",
    "model.compile(optimizer) #, metrics = [f0_midi_scaled_L1_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "z: (None, 250, 32)\n",
      "ld_scaled: (None, 250, 1)\n",
      "freq_weights: (None, 125, 1, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /kuacc/users/hbalim15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /scratch/users/hbalim15/ddsp/models.py:85 train_step  *\n        x_pred = self(x, training=True)\n    /scratch/users/hbalim15/ddsp/models.py:75 call  *\n        features = self.encode(features)\n    /scratch/users/hbalim15/ddsp/models.py:166 encode  *\n        outputs = self.encoder(features)\n    /scratch/users/hbalim15/ddsp/encoders.py:49 call  *\n        f0_hz = self.encoder_f(features)\n    /scratch/users/hbalim15/ddsp/encoders.py:117 call  *\n        freq_weights = self.resample(freq_weights)\n    /scratch/users/hbalim15/ddsp/encoders.py:147 resample  *\n        return resample(x, self.timesteps, method=\"window\")\n    /scratch/users/hbalim15/ddsp/dsp_utils/core.py:543 resample  *\n        outputs = upsample_with_windows(inputs, n_timesteps, add_endpoint)\n    /scratch/users/hbalim15/ddsp/dsp_utils/core.py:583 upsample_with_windows  *\n        raise ValueError('Upsample_with_windows() only supports 3 dimensions, '\n\n    ValueError: Upsample_with_windows() only supports 3 dimensions, not (None, 125, 1, 128).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-019d2abd36dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train, \n\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     epochs=10)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /kuacc/users/hbalim15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /scratch/users/hbalim15/ddsp/models.py:85 train_step  *\n        x_pred = self(x, training=True)\n    /scratch/users/hbalim15/ddsp/models.py:75 call  *\n        features = self.encode(features)\n    /scratch/users/hbalim15/ddsp/models.py:166 encode  *\n        outputs = self.encoder(features)\n    /scratch/users/hbalim15/ddsp/encoders.py:49 call  *\n        f0_hz = self.encoder_f(features)\n    /scratch/users/hbalim15/ddsp/encoders.py:117 call  *\n        freq_weights = self.resample(freq_weights)\n    /scratch/users/hbalim15/ddsp/encoders.py:147 resample  *\n        return resample(x, self.timesteps, method=\"window\")\n    /scratch/users/hbalim15/ddsp/dsp_utils/core.py:543 resample  *\n        outputs = upsample_with_windows(inputs, n_timesteps, add_endpoint)\n    /scratch/users/hbalim15/ddsp/dsp_utils/core.py:583 upsample_with_windows  *\n        raise ValueError('Upsample_with_windows() only supports 3 dimensions, '\n\n    ValueError: Upsample_with_windows() only supports 3 dimensions, not (None, 125, 1, 128).\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, \n",
    "                    validation_data=val, \n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 250\n",
    "\n",
    "encoder_z = Encoder_z(timesteps=timesteps)\n",
    "encoder_f0 = Encoder_f(timesteps=timesteps)\n",
    "\n",
    "decoder = DecoderWithLatent()\n",
    "\n",
    "preprocessor = MidiF0LoudnessPreprocessor(timesteps=timesteps)\n",
    "\n",
    "#loss = SpectralLoss(logmag_weight=1.0)\n",
    "loss = MultiLoss(logmag_weight=1.0, perceptual_loss_weight=38)\n",
    "\n",
    "metric_fns = {\"F0_recons_L1\": f0_midi_scaled_L1_loss}\n",
    "\n",
    "model = UnsupervisedAutoencoder(preprocessor=preprocessor,\n",
    "                                encoder_f0=encoder_f0,\n",
    "                                encoder_z=encoder_z,\n",
    "                                decoder=decoder,\n",
    "                                loss_fn=loss,\n",
    "                                tracker_names=[\"total_loss\", \"spec_loss\", \"perc_loss\",\"F0_recons_L1\"],\n",
    "                                metric_fns=metric_fns)\n",
    "\n",
    "decay = ExponentialDecay(1e-3, decay_steps=10000, decay_rate=0.98)\n",
    "adam = Adam(learning_rate=decay)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\"logs/{}.csv\".format(RUN_NAME), separator=\",\", append=False)\n",
    "\n",
    "callbacks = [ModelCheckpoint(model, RUN_NAME), csv_logger, CustomWandbCallback(RUN_NAME)]\n",
    "\n",
    "model.compile(adam, metrics = [f0_midi_scaled_L1_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_set, \n",
    "                    validation_data=validation_set,\n",
    "                    callbacks=callbacks, \n",
    "                    epochs=1000,\n",
    "                    steps_per_epoch=train_set.my_len,\n",
    "                    validation_steps=validation_set.my_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = make_unsupervised_dataset('../audio_clips/Violin_short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import UnsupervisedPreprocessor\n",
    "from train_utils import make_unsupervised_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = UnsupervisedPreprocessor(timesteps=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = preprocessor(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/Unsupervised_Violin.yaml') as file:\n",
    "    config = dict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = make_unsupervised_model(config)\n",
    "optimizer = Adam(learning_rate=ExponentialDecay(config['optimizer']['lr'],\n",
    "                            decay_steps=config['optimizer']['decay_steps'],\n",
    "                            decay_rate=config['optimizer']['decay_rate']))\n",
    "\n",
    "# Model Saving and Experiment Tracking\n",
    "if config['loss']['type'] == 'spectral':\n",
    "    monitor = 'val_spec_loss'\n",
    "else:\n",
    "    monitor = 'val_total_loss' \n",
    "#callbacks = create_callbacks(config, monitor)\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer)\n",
    "print('Model Compiled.')\n",
    "history = model.fit(train,\n",
    "                    validation_data=val,\n",
    "                    #callbacks=callbacks,\n",
    "                    epochs=config['training']['epochs']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "supervised data\\\n",
    "supervised model\n",
    "\n",
    "interpolation/extrapolation (optional) \\\n",
    "test metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_filters = [128]*2 + [256]*3 + [512]*4 + [1024]*3\n",
    "#s_freqs = [1,1,2]*2 + [1,1,1,2] + [1,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(\"SupervisedViolinModel/300/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp_utils.spectral_ops import compute_mfcc, compute_logmel, compute_loudness, compute_f0\n",
    "def calculate_recons_f0_error(dataset):\n",
    "    it = iter(dataset)\n",
    "    preds,truth = [],[]\n",
    "    for batch in it:\n",
    "        pred = model(batch)\n",
    "        preds.append(pred[\"audio_synth\"].numpy())\n",
    "        truth.append(pred[\"inputs\"][\"f0_hz\"].numpy())\n",
    "    pred_f0 = [compute_f0(p[0], 16000, 250, viterbi=True)[0] for p in preds]\n",
    "    error = np.mean(np.abs(np.array(truth)[:,0,:,0]-np.array(pred_f0)))\n",
    "    hz_to_midi = core.hz_to_midi\n",
    "    F0_RANGE = spectral_ops.F0_RANGE\n",
    "    return hz_to_midi(error)/F0_RANGE\n",
    "calculate_recons_f0_error(train_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
